{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from totensor import ToTensor\n",
    "from PIL import Image\n",
    "from torchvision import get_image_backend\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_loader(video_dir_path,frame_indices):\n",
    "    video = []\n",
    "    for i in frame_indices:\n",
    "        image_path = os.path.join(video_dir_path,'image_{:05d}.jpg'.format(i))\n",
    "        if os.path.exists(image_path):\n",
    "            with open(image_path,'rb') as f:\n",
    "                with Image.open(f) as img:\n",
    "                    video.append(img.convert('RGB'))\n",
    "        else:\n",
    "            return video\n",
    "    return video\n",
    "        \n",
    "def load_value_file(file_path):\n",
    "    with open(file_path, 'r') as input_file:\n",
    "        value = float(input_file.read().rstrip('\\n\\r'))\n",
    "\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(root_path, annotation_path, subset,\n",
    "                 n_samples_for_each_video, sample_duration):\n",
    "    \n",
    "    # Load annotation data\n",
    "    with open(annotation_path,'r') as data_file:\n",
    "        data = json.load(data_file)\n",
    "\n",
    "    # get video names and annotations\n",
    "    video_names = []\n",
    "    annotations = []\n",
    "\n",
    "    \n",
    "    for key, value in data['database'].items():\n",
    "        this_subset = value['subset']\n",
    "        if this_subset == subset:\n",
    "            if subset == 'test':\n",
    "                video_names.append('test/{}'.format(key))\n",
    "            else:\n",
    "                \n",
    "                label = value['annotations']['label']\n",
    "                video_names.append('{}/{}'.format(label, key))\n",
    "                annotations.append(value['annotations'])\n",
    "                #print('{}/{}'.format(label,key),value['annotations'])\n",
    "\n",
    "    \n",
    "    # compute class to label ids \n",
    "    class_to_idx ={}\n",
    "    index = 0\n",
    "    for class_label in data['labels']:\n",
    "        class_to_idx[class_label] = index\n",
    "        index +=1\n",
    "\n",
    "        \n",
    "    # compute label to class ids\n",
    "    idx_to_class ={}\n",
    "    for name,label in class_to_idx.items():\n",
    "        idx_to_class[label] = name\n",
    "        \n",
    "    dataset = []\n",
    "    for i in range(len(video_names)):\n",
    "        if i % 1000 == 0:\n",
    "            print('dataset loading [{}/{}]'.format(i, len(video_names)))\n",
    "\n",
    "        video_path = os.path.join(root_path, video_names[i])\n",
    "        if not os.path.exists(video_path):\n",
    "            continue\n",
    "\n",
    "        n_frames_file_path = os.path.join(video_path, 'n_frames')\n",
    "        n_frames = int(load_value_file(n_frames_file_path))\n",
    "        if n_frames <= 0:\n",
    "            continue\n",
    "\n",
    "        begin_t = 1\n",
    "        end_t = n_frames\n",
    "        sample = {\n",
    "            'video': video_path,\n",
    "            'segment': [begin_t, end_t],\n",
    "            'n_frames': n_frames,\n",
    "            'video_id': video_names[i][:-14].split('/')[1]\n",
    "        }\n",
    "        if len(annotations) != 0:\n",
    "            sample['label'] = class_to_idx[annotations[i]['label']]\n",
    "        else:\n",
    "            sample['label'] = -1\n",
    "\n",
    "        if n_samples_for_each_video == 1:\n",
    "            sample['frame_indices'] = list(range(1, n_frames + 1))\n",
    "            dataset.append(sample)\n",
    "        else:\n",
    "            if n_samples_for_each_video > 1:\n",
    "                step = max(1,\n",
    "                           math.ceil((n_frames - 1 - sample_duration) /\n",
    "                                     (n_samples_for_each_video - 1)))\n",
    "                print(n_frames,step)\n",
    "            else:\n",
    "                step = sample_duration\n",
    "            for j in range(1, n_frames, step):\n",
    "                sample_j = copy.deepcopy(sample)\n",
    "                sample_j['frame_indices'] = list(\n",
    "                    range(j, min(n_frames + 1, j + sample_duration)))\n",
    "                dataset.append(sample_j)\n",
    "\n",
    "    return dataset, idx_to_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinetics Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinetics(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                root_path,\n",
    "                annotation_path,\n",
    "                subset,\n",
    "                n_samples_for_each_video=1,\n",
    "                sample_duration=16,\n",
    "                get_loader = video_loader):\n",
    "        self.data,self.class_names = make_dataset(\n",
    "            root_path,annotation_path,subset,\n",
    "            n_samples_for_each_video,sample_duration)\n",
    "        self.loader = get_loader\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        path = self.data[index]['video']\n",
    "        \n",
    "        frame_indices = self.data[index]['frame_indices']\n",
    "        \n",
    "        clip = self.loader(path,frame_indices)\n",
    "        clip = [ToTensor(1)(img) for img in clip]\n",
    "        clip = torch.stack(clip,0).permute(1,0,2,3)\n",
    "        \n",
    "        target = self.data[index]\n",
    "        \n",
    "        return clip,target\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loading [0/1135]\n",
      "dataset loading [1000/1135]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = Kinetics('/mnt/hdd/Kinetics_jpg/','3drKinetics.json','training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    training_data,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers = 4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [100., 101., 101.,  ...,   4.,   4.,   4.],\n",
      "           [ 99.,  97.,  96.,  ...,   4.,   4.,   4.],\n",
      "           [ 99.,  95.,  92.,  ...,   4.,   4.,   4.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [ 98.,  98.,  95.,  ...,   4.,   4.,   4.],\n",
      "           [ 96.,  94.,  93.,  ...,   3.,   3.,   3.],\n",
      "           [ 94.,  95.,  96.,  ...,   3.,   3.,   3.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [ 93.,  92.,  92.,  ...,   4.,   4.,   4.],\n",
      "           [ 92.,  92.,  95.,  ...,   3.,   3.,   3.],\n",
      "           [ 94.,  94.,  95.,  ...,   3.,   3.,   3.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   7.,   7.,   7.],\n",
      "           [  1.,   1.,   1.,  ...,   7.,   7.,   7.],\n",
      "           [  1.,   1.,   1.,  ...,   7.,   7.,   7.],\n",
      "           ...,\n",
      "           [102., 124., 154.,  ...,   1.,   1.,   1.],\n",
      "           [104., 123., 150.,  ...,   1.,   1.,   1.],\n",
      "           [105., 123., 148.,  ...,   1.,   1.,   1.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   6.,   6.,   6.],\n",
      "           [  1.,   1.,   1.,  ...,   6.,   6.,   6.],\n",
      "           [  1.,   1.,   1.,  ...,   6.,   6.,   6.],\n",
      "           ...,\n",
      "           [174., 129.,  80.,  ...,   1.,   1.,   1.],\n",
      "           [185., 139.,  88.,  ...,   1.,   1.,   1.],\n",
      "           [201., 153.,  98.,  ...,   1.,   1.,   1.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   4.,   4.,   4.],\n",
      "           [  1.,   1.,   1.,  ...,   4.,   4.,   4.],\n",
      "           [  1.,   1.,   1.,  ...,   4.,   4.,   4.],\n",
      "           ...,\n",
      "           [ 86.,  88.,  89.,  ...,   1.,   1.,   1.],\n",
      "           [ 87.,  89.,  89.,  ...,   1.,   1.,   1.],\n",
      "           [ 81.,  82.,  82.,  ...,   1.,   1.,   1.]]],\n",
      "\n",
      "\n",
      "         [[[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [ 98.,  99.,  99.,  ...,   4.,   4.,   4.],\n",
      "           [ 97.,  95.,  94.,  ...,   4.,   4.,   4.],\n",
      "           [ 97.,  93.,  90.,  ...,   4.,   4.,   4.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [ 98.,  98.,  95.,  ...,   4.,   4.,   4.],\n",
      "           [ 96.,  94.,  93.,  ...,   3.,   3.,   3.],\n",
      "           [ 94.,  95.,  96.,  ...,   3.,   3.,   3.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [ 93.,  92.,  92.,  ...,   4.,   4.,   4.],\n",
      "           [ 92.,  92.,  95.,  ...,   3.,   3.,   3.],\n",
      "           [ 94.,  94.,  95.,  ...,   3.,   3.,   3.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   6.,   6.,   6.],\n",
      "           [  1.,   1.,   1.,  ...,   6.,   6.,   6.],\n",
      "           [  1.,   1.,   1.,  ...,   6.,   6.,   6.],\n",
      "           ...,\n",
      "           [ 92., 113., 143.,  ...,   1.,   1.,   1.],\n",
      "           [ 94., 112., 139.,  ...,   1.,   1.,   1.],\n",
      "           [ 95., 112., 137.,  ...,   1.,   1.,   1.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   5.,   5.,   5.],\n",
      "           [  1.,   1.,   1.,  ...,   5.,   5.,   5.],\n",
      "           [  1.,   1.,   1.,  ...,   5.,   5.,   5.],\n",
      "           ...,\n",
      "           [164., 119.,  70.,  ...,   1.,   1.,   1.],\n",
      "           [175., 129.,  78.,  ...,   1.,   1.,   1.],\n",
      "           [191., 143.,  88.,  ...,   1.,   1.,   1.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   5.,   5.,   5.],\n",
      "           [  1.,   1.,   1.,  ...,   5.,   5.,   5.],\n",
      "           [  1.,   1.,   1.,  ...,   5.,   5.,   5.],\n",
      "           ...,\n",
      "           [ 77.,  79.,  80.,  ...,   1.,   1.,   1.],\n",
      "           [ 78.,  80.,  80.,  ...,   1.,   1.,   1.],\n",
      "           [ 72.,  73.,  73.,  ...,   1.,   1.,   1.]]],\n",
      "\n",
      "\n",
      "         [[[  1.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
      "           [  1.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
      "           [  1.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
      "           ...,\n",
      "           [103., 104., 104.,  ...,   2.,   2.,   2.],\n",
      "           [102., 100.,  99.,  ...,   2.,   2.,   2.],\n",
      "           [102.,  98.,  95.,  ...,   2.,   2.,   2.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [100., 100.,  97.,  ...,   2.,   2.,   2.],\n",
      "           [ 98.,  96.,  95.,  ...,   1.,   1.,   1.],\n",
      "           [ 96.,  97.,  98.,  ...,   1.,   1.,   1.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [ 95.,  94.,  94.,  ...,   2.,   2.,   2.],\n",
      "           [ 94.,  94.,  97.,  ...,   1.,   1.,   1.],\n",
      "           [ 96.,  96.,  97.,  ...,   1.,   1.,   1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   4.,   4.,   4.],\n",
      "           [  1.,   1.,   1.,  ...,   4.,   4.,   4.],\n",
      "           [  1.,   1.,   1.,  ...,   4.,   4.,   4.],\n",
      "           ...,\n",
      "           [ 67.,  91., 121.,  ...,   0.,   0.,   0.],\n",
      "           [ 69.,  90., 117.,  ...,   0.,   0.,   0.],\n",
      "           [ 70.,  90., 115.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           [  1.,   1.,   1.,  ...,   1.,   1.,   1.],\n",
      "           ...,\n",
      "           [163., 118.,  69.,  ...,   0.,   0.,   0.],\n",
      "           [174., 128.,  77.,  ...,   0.,   0.,   0.],\n",
      "           [190., 142.,  87.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "          [[  1.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
      "           [  1.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
      "           [  1.,   1.,   1.,  ...,   0.,   0.,   0.],\n",
      "           ...,\n",
      "           [ 80.,  82.,  83.,  ...,   0.,   0.,   0.],\n",
      "           [ 81.,  83.,  83.,  ...,   0.,   0.,   0.],\n",
      "           [ 75.,  76.,  76.,  ...,   0.,   0.,   0.]]]]])\n",
      "{'video': ['/mnt/hdd/Kinetics_jpg/acting in play/AfVpAP8WoMs_000023_000033'], 'segment': [tensor([1]), tensor([300])], 'n_frames': tensor([300]), 'video_id': ['AfVpAP8WoMs'], 'label': tensor([0]), 'frame_indices': [tensor([1]), tensor([2]), tensor([3]), tensor([4]), tensor([5]), tensor([6]), tensor([7]), tensor([8]), tensor([9]), tensor([10]), tensor([11]), tensor([12]), tensor([13]), tensor([14]), tensor([15]), tensor([16]), tensor([17]), tensor([18]), tensor([19]), tensor([20]), tensor([21]), tensor([22]), tensor([23]), tensor([24]), tensor([25]), tensor([26]), tensor([27]), tensor([28]), tensor([29]), tensor([30]), tensor([31]), tensor([32]), tensor([33]), tensor([34]), tensor([35]), tensor([36]), tensor([37]), tensor([38]), tensor([39]), tensor([40]), tensor([41]), tensor([42]), tensor([43]), tensor([44]), tensor([45]), tensor([46]), tensor([47]), tensor([48]), tensor([49]), tensor([50]), tensor([51]), tensor([52]), tensor([53]), tensor([54]), tensor([55]), tensor([56]), tensor([57]), tensor([58]), tensor([59]), tensor([60]), tensor([61]), tensor([62]), tensor([63]), tensor([64]), tensor([65]), tensor([66]), tensor([67]), tensor([68]), tensor([69]), tensor([70]), tensor([71]), tensor([72]), tensor([73]), tensor([74]), tensor([75]), tensor([76]), tensor([77]), tensor([78]), tensor([79]), tensor([80]), tensor([81]), tensor([82]), tensor([83]), tensor([84]), tensor([85]), tensor([86]), tensor([87]), tensor([88]), tensor([89]), tensor([90]), tensor([91]), tensor([92]), tensor([93]), tensor([94]), tensor([95]), tensor([96]), tensor([97]), tensor([98]), tensor([99]), tensor([100]), tensor([101]), tensor([102]), tensor([103]), tensor([104]), tensor([105]), tensor([106]), tensor([107]), tensor([108]), tensor([109]), tensor([110]), tensor([111]), tensor([112]), tensor([113]), tensor([114]), tensor([115]), tensor([116]), tensor([117]), tensor([118]), tensor([119]), tensor([120]), tensor([121]), tensor([122]), tensor([123]), tensor([124]), tensor([125]), tensor([126]), tensor([127]), tensor([128]), tensor([129]), tensor([130]), tensor([131]), tensor([132]), tensor([133]), tensor([134]), tensor([135]), tensor([136]), tensor([137]), tensor([138]), tensor([139]), tensor([140]), tensor([141]), tensor([142]), tensor([143]), tensor([144]), tensor([145]), tensor([146]), tensor([147]), tensor([148]), tensor([149]), tensor([150]), tensor([151]), tensor([152]), tensor([153]), tensor([154]), tensor([155]), tensor([156]), tensor([157]), tensor([158]), tensor([159]), tensor([160]), tensor([161]), tensor([162]), tensor([163]), tensor([164]), tensor([165]), tensor([166]), tensor([167]), tensor([168]), tensor([169]), tensor([170]), tensor([171]), tensor([172]), tensor([173]), tensor([174]), tensor([175]), tensor([176]), tensor([177]), tensor([178]), tensor([179]), tensor([180]), tensor([181]), tensor([182]), tensor([183]), tensor([184]), tensor([185]), tensor([186]), tensor([187]), tensor([188]), tensor([189]), tensor([190]), tensor([191]), tensor([192]), tensor([193]), tensor([194]), tensor([195]), tensor([196]), tensor([197]), tensor([198]), tensor([199]), tensor([200]), tensor([201]), tensor([202]), tensor([203]), tensor([204]), tensor([205]), tensor([206]), tensor([207]), tensor([208]), tensor([209]), tensor([210]), tensor([211]), tensor([212]), tensor([213]), tensor([214]), tensor([215]), tensor([216]), tensor([217]), tensor([218]), tensor([219]), tensor([220]), tensor([221]), tensor([222]), tensor([223]), tensor([224]), tensor([225]), tensor([226]), tensor([227]), tensor([228]), tensor([229]), tensor([230]), tensor([231]), tensor([232]), tensor([233]), tensor([234]), tensor([235]), tensor([236]), tensor([237]), tensor([238]), tensor([239]), tensor([240]), tensor([241]), tensor([242]), tensor([243]), tensor([244]), tensor([245]), tensor([246]), tensor([247]), tensor([248]), tensor([249]), tensor([250]), tensor([251]), tensor([252]), tensor([253]), tensor([254]), tensor([255]), tensor([256]), tensor([257]), tensor([258]), tensor([259]), tensor([260]), tensor([261]), tensor([262]), tensor([263]), tensor([264]), tensor([265]), tensor([266]), tensor([267]), tensor([268]), tensor([269]), tensor([270]), tensor([271]), tensor([272]), tensor([273]), tensor([274]), tensor([275]), tensor([276]), tensor([277]), tensor([278]), tensor([279]), tensor([280]), tensor([281]), tensor([282]), tensor([283]), tensor([284]), tensor([285]), tensor([286]), tensor([287]), tensor([288]), tensor([289]), tensor([290]), tensor([291]), tensor([292]), tensor([293]), tensor([294]), tensor([295]), tensor([296]), tensor([297]), tensor([298]), tensor([299]), tensor([300])]}\n"
     ]
    }
   ],
   "source": [
    "for  (inputs,targets) in train_loader:\n",
    "    print(inputs)\n",
    "    print(targets)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
